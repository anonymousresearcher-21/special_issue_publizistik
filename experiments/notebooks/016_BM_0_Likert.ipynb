{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß™ SLR Abstract Screening Experiment\n",
        "#### Experiment Information\n",
        "- **ID**: 016\n",
        "- **Date**: 08/14\n",
        "#### üéØ Goal\n",
        "- \n",
        "#### ‚öôÔ∏è Configuration\n",
        "- **LLM** : GPT-4o\n",
        "- **Data**: BM\n",
        "- **Examples** : 0\n",
        "- **Output**: Likert\n",
        "#### üìù Notes\n",
        "- \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîß Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Essential imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "# Configure pandas display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_theme()  # This is the correct way to set seaborn style\n",
        "plt.rcParams['figure.figsize'] = (12, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì First dataset loaded successfully\n",
            "‚úì Shape of dataset 1: (3944, 15)\n",
            "\n",
            "‚úì Second dataset loaded successfully\n",
            "‚úì Shape of dataset 2: (917, 13)\n",
            "\n",
            "First few rows of dataset 1:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>abstract</th>\n",
              "      <th>acmid</th>\n",
              "      <th>author</th>\n",
              "      <th>doi</th>\n",
              "      <th>outlet</th>\n",
              "      <th>title_full</th>\n",
              "      <th>url</th>\n",
              "      <th>year</th>\n",
              "      <th>qualtrics_id</th>\n",
              "      <th>wos_id</th>\n",
              "      <th>ebsco_id</th>\n",
              "      <th>stage_1</th>\n",
              "      <th>stage_2</th>\n",
              "      <th>stage_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bindu2018503</td>\n",
              "      <td>Online social networks have become immensely p...</td>\n",
              "      <td></td>\n",
              "      <td>Bindu, P V and Mishra, R and Thilagam, P S</td>\n",
              "      <td>10.1007/s10844-017-0494-z</td>\n",
              "      <td>Journal of Intelligent Information Systems</td>\n",
              "      <td>{Discovering spammer communities in TWITTER}</td>\n",
              "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
              "      <td>2018</td>\n",
              "      <td>12</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Moraga2018470</td>\n",
              "      <td>This article explores the ways Latinos‚Äîas audi...</td>\n",
              "      <td></td>\n",
              "      <td>Moraga, J E</td>\n",
              "      <td>10.1177/0193723518797030</td>\n",
              "      <td>Journal of Sport and Social Issues</td>\n",
              "      <td>{On ESPN Deportes: Latinos, Sport MEDIA, and t...</td>\n",
              "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
              "      <td>2018</td>\n",
              "      <td>22</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lanosga20181676</td>\n",
              "      <td>This study of American investigative reporting...</td>\n",
              "      <td></td>\n",
              "      <td>Lanosga, G and Martin, J</td>\n",
              "      <td>10.1177/1464884916683555</td>\n",
              "      <td>JOURNALISm</td>\n",
              "      <td>{JOURNALISts, sources, and policy outcomes: In...</td>\n",
              "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
              "      <td>2018</td>\n",
              "      <td>47</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Warner2018720</td>\n",
              "      <td>In this study, we test the indirect and condit...</td>\n",
              "      <td></td>\n",
              "      <td>Warner, B R and Jennings, F J and Bramlett, J ...</td>\n",
              "      <td>10.1080/15205436.2018.1472283</td>\n",
              "      <td>Mass Communication and Society</td>\n",
              "      <td>{A MultiMEDIA Analysis of Persuasion in the 20...</td>\n",
              "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
              "      <td>2018</td>\n",
              "      <td>50</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Burrows20181117</td>\n",
              "      <td>Professional communicators produce a diverse r...</td>\n",
              "      <td></td>\n",
              "      <td>Burrows, E</td>\n",
              "      <td>10.1177/0163443718764807</td>\n",
              "      <td>MEDIA, Culture and Society</td>\n",
              "      <td>{Indigenous MEDIA producers' perspectives on o...</td>\n",
              "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
              "      <td>2018</td>\n",
              "      <td>56</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                ID                                           abstract acmid                                             author                            doi                                      outlet                                         title_full                                                url  year qualtrics_id wos_id ebsco_id  stage_1  stage_2  stage_3\n",
              "0     Bindu2018503  Online social networks have become immensely p...               Bindu, P V and Mishra, R and Thilagam, P S      10.1007/s10844-017-0494-z  Journal of Intelligent Information Systems       {Discovering spammer communities in TWITTER}  https://www.scopus.com/inward/record.uri?eid=2...  2018           12             NaN     True    False    False\n",
              "1    Moraga2018470  This article explores the ways Latinos‚Äîas audi...                                              Moraga, J E       10.1177/0193723518797030          Journal of Sport and Social Issues  {On ESPN Deportes: Latinos, Sport MEDIA, and t...  https://www.scopus.com/inward/record.uri?eid=2...  2018           22             NaN     True    False    False\n",
              "2  Lanosga20181676  This study of American investigative reporting...                                 Lanosga, G and Martin, J       10.1177/1464884916683555                                  JOURNALISm  {JOURNALISts, sources, and policy outcomes: In...  https://www.scopus.com/inward/record.uri?eid=2...  2018           47             NaN     True    False     True\n",
              "3    Warner2018720  In this study, we test the indirect and condit...        Warner, B R and Jennings, F J and Bramlett, J ...  10.1080/15205436.2018.1472283              Mass Communication and Society  {A MultiMEDIA Analysis of Persuasion in the 20...  https://www.scopus.com/inward/record.uri?eid=2...  2018           50             NaN     True    False    False\n",
              "4  Burrows20181117  Professional communicators produce a diverse r...                                               Burrows, E       10.1177/0163443718764807                  MEDIA, Culture and Society  {Indigenous MEDIA producers' perspectives on o...  https://www.scopus.com/inward/record.uri?eid=2...  2018           56             NaN     True    False    False"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "First few rows of dataset 2:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(internal) id</th>\n",
              "      <th>(source) id</th>\n",
              "      <th>abstract</th>\n",
              "      <th>title_full</th>\n",
              "      <th>journal</th>\n",
              "      <th>authors</th>\n",
              "      <th>tags</th>\n",
              "      <th>consensus</th>\n",
              "      <th>labeled_at...9</th>\n",
              "      <th>code</th>\n",
              "      <th>stage_1</th>\n",
              "      <th>stage_2</th>\n",
              "      <th>stage_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33937314</td>\n",
              "      <td>175</td>\n",
              "      <td>There is a worry that serious forms of politic...</td>\n",
              "      <td>Is Context the Key? The (Non-)Differential Eff...</td>\n",
              "      <td>Polit. Commun.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>o</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33937315</td>\n",
              "      <td>113</td>\n",
              "      <td>The electoral model of democracy holds the ide...</td>\n",
              "      <td>POLITICAL NEWS IN ONLINE AND PRINT NEWSPAPERS ...</td>\n",
              "      <td>Digit. Journal.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>o</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33937316</td>\n",
              "      <td>122</td>\n",
              "      <td>Machine learning is a field at the intersectio...</td>\n",
              "      <td>Machine Learning for Sociology</td>\n",
              "      <td>Annu. Rev. Sociol.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>o</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33937317</td>\n",
              "      <td>467</td>\n",
              "      <td>Research on digital glocalization has found th...</td>\n",
              "      <td>Improving Health in Low-Income Communities Wit...</td>\n",
              "      <td>J. Commun.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>o</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33937318</td>\n",
              "      <td>10</td>\n",
              "      <td>Political scientists often wish to classify do...</td>\n",
              "      <td>Using Word Order in Political Text Classificat...</td>\n",
              "      <td>Polit. Anal.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>o</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   (internal) id  (source) id                                           abstract                                         title_full             journal authors  tags consensus  labeled_at...9  code  stage_1  stage_2  stage_3\n",
              "0       33937314          175  There is a worry that serious forms of politic...  Is Context the Key? The (Non-)Differential Eff...      Polit. Commun.     NaN   NaN         o             NaN    -1     True    False    False\n",
              "1       33937315          113  The electoral model of democracy holds the ide...  POLITICAL NEWS IN ONLINE AND PRINT NEWSPAPERS ...     Digit. Journal.     NaN   NaN         o             NaN    -1     True    False    False\n",
              "2       33937316          122  Machine learning is a field at the intersectio...                     Machine Learning for Sociology  Annu. Rev. Sociol.     NaN   NaN         o             NaN    -1     True    False    False\n",
              "3       33937317          467  Research on digital glocalization has found th...  Improving Health in Low-Income Communities Wit...          J. Commun.     NaN   NaN         o             NaN    -1     True    False    False\n",
              "4       33937318           10  Political scientists often wish to classify do...  Using Word Order in Political Text Classificat...        Polit. Anal.     NaN   NaN         o             NaN    -1     True    False    False"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Data Import \n",
        "\n",
        "# Define the data paths for both datasets\n",
        "DATA_PATH_1 = \"../data/SSOT_manual_LB_20250808_120908.csv\" # ‚¨ÖÔ∏è Change this path if needed\n",
        "DATA_PATH_2 = \"../data/SSOT_manual_BM_20250813_132621.csv\" # ‚¨ÖÔ∏è Change this path if needed\n",
        "\n",
        "# Load the first dataset (df1)\n",
        "try:\n",
        "    df_LB = pd.read_csv(DATA_PATH_1)\n",
        "    print(f\"‚úì First dataset loaded successfully\")\n",
        "    print(f\"‚úì Shape of dataset 1: {df_LB.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: The file LB dataset was not found in the data directory\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading the first dataset: {str(e)}\")\n",
        "\n",
        "# Load the second dataset (df2)\n",
        "try:\n",
        "    df_BM = pd.read_csv(DATA_PATH_2)\n",
        "    print(f\"\\n‚úì Second dataset loaded successfully\")\n",
        "    print(f\"‚úì Shape of dataset 2: {df_BM.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: The file df_BM was not found in the data directory\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading the second dataset: {str(e)}\")\n",
        "\n",
        "# Display basic information about both datasets\n",
        "print(\"\\nFirst few rows of dataset 1:\\n\")\n",
        "display(df_LB.head())\n",
        "\n",
        "print(\"\\nFirst few rows of dataset 2:\\n\")\n",
        "display(df_BM.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß´ Define Experiment Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ EXPERIMENT SETUP\n",
            "==================================================\n",
            "ID: 016\n",
            "Date: 2025-08-14\n",
            "Category: Testing\n",
            "üéØGoal: Test Set Up\n",
            "Model: gpt-4o (temp=0.0)\n",
            "==================================================\n",
            "‚úÖ Experiment configuration loaded\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Experiment Metadata\n",
        "EXPERIMENT_ID = \"016\"  # ‚¨ÖÔ∏è Change this for each new experiment\n",
        "EXPERIMENT_DATE = \"2025-08-14\"  # ‚¨ÖÔ∏è Update the date\n",
        "EXPERIMENT_CATEGORY = \"Testing\"  # ‚¨ÖÔ∏è Category of experiment\n",
        "EXPERIMENT_GOAL = \"Test Set Up\"  # ‚¨ÖÔ∏è What are you testing?\n",
        "\n",
        "# Model Configuration\n",
        "MODEL_NAME = \"gpt-4o\"\n",
        "TEMPERATURE = 0.0\n",
        "MAX_TOKENS = 4000\n",
        "\n",
        "# Print experiment info\n",
        "print(\"üß™ EXPERIMENT SETUP\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"ID: {EXPERIMENT_ID}\")\n",
        "print(f\"Date: {EXPERIMENT_DATE}\")\n",
        "print(f\"Category: {EXPERIMENT_CATEGORY}\")\n",
        "print(f\"üéØGoal: {EXPERIMENT_GOAL}\")\n",
        "print(f\"Model: {MODEL_NAME} (temp={TEMPERATURE})\")\n",
        "print(\"=\" * 50)\n",
        "print(\"‚úÖ Experiment configuration loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì£ Set up Basic API Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ OpenAI API Key loaded successfully.\n",
            "‚úÖ OpenAI client initialized.\n",
            "‚úÖ Enhanced screening function defined.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from datetime import datetime\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Get the API key from environment variables\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Validate API key\n",
        "if not api_key:\n",
        "    print(\"‚ö†Ô∏è  Error: OPENAI_API_KEY not found.\")\n",
        "    print(\"Please make sure you have a .env file with OPENAI_API_KEY='sk-...'\")\n",
        "else:\n",
        "    print(\"‚úÖ OpenAI API Key loaded successfully.\")\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    print(\"‚úÖ OpenAI client initialized.\")\n",
        "\n",
        "# Enhanced analysis function for abstract screening\n",
        "def screen_abstract_llm(abstract_text, system_prompt, user_prompt_template, \n",
        "                       model=\"gpt-4o\", temperature=0.0):\n",
        "    \"\"\"\n",
        "    Screen an abstract using LLM with system and user prompts.\n",
        "    \n",
        "    Args:\n",
        "        abstract_text (str): The abstract to analyze\n",
        "        system_prompt (str): The system prompt defining the role\n",
        "        user_prompt_template (str): Template with {abstract} placeholder\n",
        "        model (str): The OpenAI model to use\n",
        "        temperature (float): Temperature setting for response randomness\n",
        "    \n",
        "    Returns:\n",
        "        dict: Result with decision, reasoning, and metadata\n",
        "    \"\"\"\n",
        "    if 'client' not in globals():\n",
        "        return {\"error\": \"OpenAI client is not initialized. Please check your API key.\"}\n",
        "\n",
        "    try:\n",
        "        # Insert abstract into user prompt template\n",
        "        user_prompt = user_prompt_template.format(abstract=abstract_text)\n",
        "        \n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=4000\n",
        "        )\n",
        "        \n",
        "        if response and response.choices:\n",
        "            result = {\n",
        "                \"decision\": \"INCLUDE\" if \"INCLUDE\" in response.choices[0].message.content.upper() else \"EXCLUDE\",\n",
        "                \"reasoning\": response.choices[0].message.content,\n",
        "                \"model\": model,\n",
        "                \"temperature\": temperature,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"error\": None\n",
        "            }\n",
        "            return result\n",
        "        else:\n",
        "            return {\"error\": \"API Error: Empty or invalid response.\"}\n",
        "            \n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"API Error: {e}\"}\n",
        "\n",
        "print(\"‚úÖ Enhanced screening function defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèõÔ∏è Set Up System Prompt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ System prompt defined\n",
            "üìã ID: SYS_001\n",
            "üìè Length: 759 characters\n",
            "üìÑ Description: Generic expert literature review screener for systematic reviews\n"
          ]
        }
      ],
      "source": [
        "# System prompt configuration\n",
        "# System prompt configuration\n",
        "SYSTEM_PROMPT_ID = \"SYS_001\"  # ‚¨ÖÔ∏è Change this ID for different system prompts\n",
        "SYSTEM_PROMPT_DESCRIPTION = \"Generic expert literature review screener for systematic reviews\"\n",
        "\n",
        "# Define the system prompt that sets the LLM's role\n",
        "SYSTEM_PROMPT = \"\"\"You are an expert in scientific literature review and systematic review methodology.\n",
        "\n",
        "Your task is to screen research abstracts and decide whether they should be INCLUDED or EXCLUDED from a systematic literature review based on provided criteria.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Carefully read the provided inclusion/exclusion criteria\n",
        "2. Review any example abstracts to understand the decision-making pattern\n",
        "3. Apply the criteria systematically to the given abstract and title\n",
        "4. Provide your decision in the exact format requested\n",
        "5. Base your reasoning strictly on the provided criteria\n",
        "\n",
        "Be consistent, objective, and systematic in your evaluation. Do not make up additional criteria beyond what is provided. Focus only on what is explicitly stated in the instructions.\"\"\"\n",
        "\n",
        "print(f\"‚úÖ System prompt defined\")\n",
        "print(f\"üìã ID: {SYSTEM_PROMPT_ID}\")\n",
        "print(f\"üìè Length: {len(SYSTEM_PROMPT)} characters\")\n",
        "print(f\"üìÑ Description: {SYSTEM_PROMPT_DESCRIPTION}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üë©üèª‚Äç‚öïÔ∏è Create User Prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ User prompt configuration and template loaded\n",
            "üìã ID: USR_005\n",
            "üìÑ Description: Basic screening with criteria, no examples from CSV files, Likert 1-5 relevance scale\n",
            "üìÅ Criteria: ../prompts/Criteria_BM_01.csv\n",
            "üìÅ Examples: None\n",
            "üéØ Output: Likert\n",
            "üî¨ Topic: Computational Text Analysis Methods | Domain: political_communication | Source: BM\n",
            "üìè Template length: 1601 characters\n"
          ]
        }
      ],
      "source": [
        "# User prompt configuration\n",
        "USER_PROMPT_ID = \"USR_005\"  # ‚¨ÖÔ∏è Change this ID for different user prompts\n",
        "USER_PROMPT_DESCRIPTION = \"Basic screening with criteria, no examples from CSV files, Likert 1-5 relevance scale\"\n",
        "\n",
        "# File paths for modular components\n",
        "CRITERIA_FILE = \"../prompts/Criteria_BM_01.csv\"  # ‚¨ÖÔ∏è Change criteria file here\n",
        "EXAMPLES_FILE = None  # ‚¨ÖÔ∏è Change examples file here (or set to None)\n",
        "\n",
        "# Output configuration\n",
        "OUTPUT_FORMAT = \"Likert\"  # ‚¨ÖÔ∏è Options: \"Binary\", \"Yes/Maybe/No\", \"Likert\"\n",
        "DECISION_OPTIONS = [\"1\", \"2\", \"3\", \"4\", \"5\"] # ‚¨ÖÔ∏è Change according to the output format\n",
        "\n",
        "# Additional metadata for results tracking\n",
        "DOMAIN = \"political_communication\" # ‚¨ÖÔ∏è Change this to the domain of the study\n",
        "TOPIC = \"Computational Text Analysis Methods\"  # ‚¨ÖÔ∏è Change this to the topic of the study\n",
        "DATASET_SOURCE = \"BM\"  # ‚¨ÖÔ∏è Which dataset (BM/LB)\n",
        "\n",
        "# Define the user prompt template with placeholders\n",
        "USER_PROMPT_TEMPLATE = \"\"\"## SCREENING TASK:\n",
        "You are screening abstracts for a systematic literature review on {topic} in {domain}. Your task is to evaluate the relevance of each abstract based on how well it meets the inclusion criteria.\n",
        "\n",
        "## INCLUSION/EXCLUSION CRITERIA:\n",
        "{criteria_text}\n",
        "\n",
        "{examples_section}\n",
        "\n",
        "## RELEVANCE SCALE:\n",
        "Rate the relevance of each abstract on a scale from 1 to 5:\n",
        "\n",
        "**5 - Highly Relevant**: Abstract clearly and strongly meets all inclusion criteria. Definitely should be included.\n",
        "\n",
        "**4 - Relevant**: Abstract meets most inclusion criteria with good alignment to the research focus. Should likely be included.\n",
        "\n",
        "**3 - Moderately Relevant**: Abstract shows some relevance but has unclear aspects or partial alignment with criteria. Requires careful consideration.\n",
        "\n",
        "**2 - Minimally Relevant**: Abstract has limited relevance, meets few criteria, or has significant gaps. Should likely be excluded.\n",
        "\n",
        "**1 - Not Relevant**: Abstract clearly does not meet inclusion criteria or is completely outside the research scope. Definitely should be excluded.\n",
        "\n",
        "## ABSTRACT TO SCREEN:\n",
        "**Title:** {title}\n",
        "**Abstract:** {abstract}\n",
        "\n",
        "## YOUR EVALUATION:\n",
        "Provide your relevance rating and detailed reasoning:\n",
        "\n",
        "**Relevance Score:** [Choose exactly one number: 1, 2, 3, 4, or 5]\n",
        "\n",
        "**Reasoning:** [Explain your rating by specifically addressing how the abstract aligns with each inclusion/exclusion criterion. For scores of 3, clearly identify what information would be needed to make a definitive decision. For scores of 1-2, specify which criteria are not met. For scores of 4-5, highlight the strong alignment with criteria.]\"\"\"\n",
        "\n",
        "print(f\"‚úÖ User prompt configuration and template loaded\")\n",
        "print(f\"üìã ID: {USER_PROMPT_ID}\")\n",
        "print(f\"üìÑ Description: {USER_PROMPT_DESCRIPTION}\")\n",
        "print(f\"üìÅ Criteria: {CRITERIA_FILE}\")\n",
        "print(f\"üìÅ Examples: {EXAMPLES_FILE}\")\n",
        "print(f\"üéØ Output: {OUTPUT_FORMAT}\")\n",
        "print(f\"üî¨ Topic: {TOPIC} | Domain: {DOMAIN} | Source: {DATASET_SOURCE}\")\n",
        "print(f\"üìè Template length: {len(USER_PROMPT_TEMPLATE)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Valdiation Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç VALIDATION CHECK\n",
            "==================================================\n",
            "üìã Checking required variables:\n",
            "   ‚úÖ EXPERIMENT_ID: 016\n",
            "   ‚úÖ SYSTEM_PROMPT_ID: SYS_001\n",
            "   ‚úÖ USER_PROMPT_ID: USR_005\n",
            "   ‚úÖ SYSTEM_PROMPT: You are an expert in scientific literature review ...\n",
            "   ‚úÖ USER_PROMPT_TEMPLATE: ## SCREENING TASK:\n",
            "You are screening abstracts for...\n",
            "   ‚úÖ CRITERIA_FILE: ../prompts/Criteria_BM_01.csv\n",
            "   ‚úÖ DECISION_OPTIONS: ['1', '2', '3', '4', '5']\n",
            "   ‚úÖ MODEL_NAME: gpt-4o\n",
            "   ‚úÖ TEMPERATURE: 0.0\n",
            "   ‚úÖ TOPIC: Computational Text Analysis Methods\n",
            "   ‚úÖ DOMAIN: political_communication\n",
            "üìã Checking optional variables:\n",
            "   ‚úÖ EXAMPLES_FILE: None (optional - will run without examples)\n",
            "\n",
            "üìä Checking DataFrame structure:\n",
            "   ‚úÖ DataFrame shape: (917, 13)\n",
            "   ‚úÖ Column 'abstract': Present\n",
            "   ‚úÖ Column 'title_full': Present\n",
            "   ‚úÖ Column 'stage_2': Present\n",
            "   ‚úÖ Column 'stage_3': Present\n",
            "\n",
            "üìà Checking data availability:\n",
            "   üìä Stage 2 True: 166\n",
            "   üìä Stage 2 False: 751\n",
            "   üìä Stage 3 True: 96\n",
            "   üìä Stage 3 False: 821\n",
            "\n",
            "üìÅ Checking file paths:\n",
            "   ‚úÖ Criteria file: ../prompts/Criteria_BM_01.csv\n",
            "   ‚úÖ Examples file: None (will run without examples)\n",
            "\n",
            "ü§ñ Checking API function:\n",
            "   ‚úÖ screen_abstract_llm function: Available\n",
            "\n",
            "==================================================\n",
            "‚úÖ ALL VALIDATIONS PASSED - Ready to run experiment!\n"
          ]
        }
      ],
      "source": [
        "def validate_experiment_setup(df, dataset_source=\"BM\"):\n",
        "    \"\"\"\n",
        "    Validate that all required variables and data are available for the experiment.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame to be used in experiment\n",
        "        dataset_source: Dataset identifier\n",
        "    \n",
        "    Returns:\n",
        "        bool: True if all validations pass, False otherwise\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"üîç VALIDATION CHECK\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    validation_passed = True\n",
        "    \n",
        "    # Check required global variables\n",
        "    required_vars = {\n",
        "        'EXPERIMENT_ID': globals().get('EXPERIMENT_ID'),\n",
        "        'SYSTEM_PROMPT_ID': globals().get('SYSTEM_PROMPT_ID'), \n",
        "        'USER_PROMPT_ID': globals().get('USER_PROMPT_ID'),\n",
        "        'SYSTEM_PROMPT': globals().get('SYSTEM_PROMPT'),\n",
        "        'USER_PROMPT_TEMPLATE': globals().get('USER_PROMPT_TEMPLATE'),\n",
        "        'CRITERIA_FILE': globals().get('CRITERIA_FILE'),\n",
        "        'DECISION_OPTIONS': globals().get('DECISION_OPTIONS'),\n",
        "        'MODEL_NAME': globals().get('MODEL_NAME'),\n",
        "        'TEMPERATURE': globals().get('TEMPERATURE'),\n",
        "        'TOPIC': globals().get('TOPIC'),\n",
        "        'DOMAIN': globals().get('DOMAIN')\n",
        "    }\n",
        "    \n",
        "    # Optional variables that can be None\n",
        "    optional_vars = {\n",
        "        'EXAMPLES_FILE': globals().get('EXAMPLES_FILE')\n",
        "    }\n",
        "    \n",
        "    print(\"üìã Checking required variables:\")\n",
        "    for var_name, var_value in required_vars.items():\n",
        "        if var_value is None:\n",
        "            print(f\"   ‚ùå {var_name}: NOT DEFINED\")\n",
        "            validation_passed = False\n",
        "        else:\n",
        "            print(f\"   ‚úÖ {var_name}: {str(var_value)[:50]}{'...' if len(str(var_value)) > 50 else ''}\")\n",
        "    \n",
        "    print(\"üìã Checking optional variables:\")\n",
        "    for var_name, var_value in optional_vars.items():\n",
        "        if var_value is None:\n",
        "            print(f\"   ‚úÖ {var_name}: None (optional - will run without examples)\")\n",
        "        else:\n",
        "            print(f\"   ‚úÖ {var_name}: {str(var_value)[:50]}{'...' if len(str(var_value)) > 50 else ''}\")\n",
        "    \n",
        "    # Check DataFrame structure\n",
        "    print(f\"\\nüìä Checking DataFrame structure:\")\n",
        "    required_columns = ['abstract', 'title_full', 'stage_2', 'stage_3']\n",
        "    \n",
        "    if df is None:\n",
        "        print(f\"   ‚ùå DataFrame is None\")\n",
        "        validation_passed = False\n",
        "    else:\n",
        "        print(f\"   ‚úÖ DataFrame shape: {df.shape}\")\n",
        "        \n",
        "        for col in required_columns:\n",
        "            if col in df.columns:\n",
        "                print(f\"   ‚úÖ Column '{col}': Present\")\n",
        "            else:\n",
        "                print(f\"   ‚ùå Column '{col}': MISSING\")\n",
        "                validation_passed = False\n",
        "    \n",
        "    # Check data availability\n",
        "    if df is not None and all(col in df.columns for col in required_columns):\n",
        "        print(f\"\\nüìà Checking data availability:\")\n",
        "        stage2_true = len(df[df['stage_2'] == True])\n",
        "        stage2_false = len(df[df['stage_2'] == False])\n",
        "        stage3_true = len(df[df['stage_3'] == True])\n",
        "        stage3_false = len(df[df['stage_3'] == False])\n",
        "        \n",
        "        print(f\"   üìä Stage 2 True: {stage2_true}\")\n",
        "        print(f\"   üìä Stage 2 False: {stage2_false}\")\n",
        "        print(f\"   üìä Stage 3 True: {stage3_true}\")\n",
        "        print(f\"   üìä Stage 3 False: {stage3_false}\")\n",
        "        \n",
        "        if stage3_true < 10:\n",
        "            print(f\"   ‚ö†Ô∏è  Warning: Only {stage3_true} stage_3=True examples available\")\n",
        "        if stage3_false < 10:\n",
        "            print(f\"   ‚ö†Ô∏è  Warning: Only {stage3_false} stage_3=False examples available\")\n",
        "    \n",
        "    # Check file paths\n",
        "    print(f\"\\nüìÅ Checking file paths:\")\n",
        "    import os\n",
        "    \n",
        "    # CRITERIA_FILE is required\n",
        "    if CRITERIA_FILE and os.path.exists(CRITERIA_FILE):\n",
        "        print(f\"   ‚úÖ Criteria file: {CRITERIA_FILE}\")\n",
        "    elif CRITERIA_FILE:\n",
        "        print(f\"   ‚ùå Criteria file: {CRITERIA_FILE} (NOT FOUND)\")\n",
        "        validation_passed = False\n",
        "    else:\n",
        "        print(f\"   ‚ùå Criteria file: NOT SPECIFIED\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    # EXAMPLES_FILE is optional\n",
        "    if EXAMPLES_FILE is None:\n",
        "        print(f\"   ‚úÖ Examples file: None (will run without examples)\")\n",
        "    elif os.path.exists(EXAMPLES_FILE):\n",
        "        print(f\"   ‚úÖ Examples file: {EXAMPLES_FILE}\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå Examples file: {EXAMPLES_FILE} (NOT FOUND)\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    # Check API function\n",
        "    print(f\"\\nü§ñ Checking API function:\")\n",
        "    if 'screen_abstract_llm' in globals():\n",
        "        print(f\"   ‚úÖ screen_abstract_llm function: Available\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå screen_abstract_llm function: NOT DEFINED\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    # Final result\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    if validation_passed:\n",
        "        print(\"‚úÖ ALL VALIDATIONS PASSED - Ready to run experiment!\")\n",
        "    else:\n",
        "        print(\"‚ùå VALIDATION FAILED - Please fix the issues above before running\")\n",
        "    \n",
        "    return validation_passed\n",
        "\n",
        "# Run validation\n",
        "validation_result = validate_experiment_setup(df_BM, \"BM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¨ Set Up Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Classification experiment function with Likert scale analysis defined\n",
            "üöÄ Ready to run: run_classification_experiment(df_BM, batch_size=20)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix \n",
        "from datetime import datetime\n",
        "import os\n",
        "import time\n",
        "\n",
        "def run_classification_experiment(\n",
        "    df, \n",
        "    n_total_examples=50,  # ‚¨ÖÔ∏è Total number of examples to test\n",
        "    n_stage3_true=5,     # ‚¨ÖÔ∏è Number of stage_3=True examples\n",
        "    n_stage3_false=45,    # ‚¨ÖÔ∏è Number of stage_3=False examples\n",
        "    dataset_source=\"BM\",  # ‚¨ÖÔ∏è Dataset identifier (LB/BM)\n",
        "    batch_size=20,        # ‚¨ÖÔ∏è Batch size for processing (max 20 to avoid timeouts)\n",
        "    save_results=True,    # ‚¨ÖÔ∏è Whether to save results to CSV\n",
        "    verbose=True          # ‚¨ÖÔ∏è Print progress updates\n",
        "):\n",
        "    \"\"\"\n",
        "    Run LLM classification experiment on abstracts with batch processing.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with abstracts (must have 'abstract', 'title_full', 'stage_2', 'stage_3')\n",
        "        n_total_examples: Total number of examples to test\n",
        "        n_stage3_true: Number of stage_3=True examples to include\n",
        "        n_stage3_false: Number of stage_3=False examples to include\n",
        "        dataset_source: Dataset identifier for results filename\n",
        "        batch_size: Number of examples to process in each batch (max 20)\n",
        "        save_results: Whether to save results to CSV\n",
        "        verbose: Whether to print progress\n",
        "    \n",
        "    Returns:\n",
        "        dict: Results including metrics and DataFrame\n",
        "    \"\"\"\n",
        "    \n",
        "    # Validate batch size\n",
        "    if batch_size > 20:\n",
        "        print(\"‚ö†Ô∏è  Warning: Batch size > 20 may cause timeouts. Setting to 20.\")\n",
        "        batch_size = 20\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"üß™ Starting Classification Experiment with Batch Processing\")\n",
        "        print(f\"üìä Dataset: {dataset_source}\")\n",
        "        print(f\"üéØ Total examples: {n_total_examples}\")\n",
        "        print(f\"‚úÖ Stage 3 True: {n_stage3_true}\")\n",
        "        print(f\"‚ùå Stage 3 False: {n_stage3_false}\")\n",
        "        print(f\"üì¶ Batch size: {batch_size}\")\n",
        "        print(\"=\" * 50)\n",
        "    \n",
        "    # Sample examples\n",
        "    stage3_true_samples = df[df['stage_3'] == True].sample(n=n_stage3_true, random_state=42)\n",
        "    stage3_false_samples = df[df['stage_3'] == False].sample(n=n_stage3_false, random_state=42)\n",
        "    \n",
        "    # Combine samples\n",
        "    test_samples = pd.concat([stage3_true_samples, stage3_false_samples]).reset_index(drop=True)\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"üìù Sampled {len(test_samples)} examples\")\n",
        "    \n",
        "    # Load criteria and examples text\n",
        "    def load_criteria_text(criteria_file):\n",
        "        try:\n",
        "            criteria_df = pd.read_csv(criteria_file)\n",
        "            criteria_text = \"\"\n",
        "            \n",
        "            # Add inclusion criteria\n",
        "            inclusion_criteria = criteria_df[criteria_df['type'] == 'inclusion']\n",
        "            if len(inclusion_criteria) > 0:\n",
        "                criteria_text += \"**INCLUSION CRITERIA:**\\n\"\n",
        "                for _, row in inclusion_criteria.iterrows():\n",
        "                    criteria_text += f\"- **{row['criterion_id']}**: {row['description']}\\n\"\n",
        "                    if pd.notna(row['examples']) and row['examples'].strip():\n",
        "                        criteria_text += f\"  *Examples: {row['examples']}*\\n\"\n",
        "            \n",
        "            # Add exclusion criteria\n",
        "            exclusion_criteria = criteria_df[criteria_df['type'] == 'exclusion']\n",
        "            if len(exclusion_criteria) > 0:\n",
        "                criteria_text += \"\\n**EXCLUSION CRITERIA:**\\n\"\n",
        "                for _, row in exclusion_criteria.iterrows():\n",
        "                    criteria_text += f\"- **{row['criterion_id']}**: {row['description']}\\n\"\n",
        "                    if pd.notna(row['examples']) and row['examples'].strip():\n",
        "                        criteria_text += f\"  *Examples: {row['examples']}*\\n\"\n",
        "            \n",
        "            return criteria_text\n",
        "        except Exception as e:\n",
        "            return f\"Error loading criteria: {e}\"\n",
        "    \n",
        "    def load_examples_text(examples_file):\n",
        "        if not examples_file:\n",
        "            return \"\"\n",
        "        try:\n",
        "            examples_df = pd.read_csv(examples_file)\n",
        "            examples_text = \"\\n## EXAMPLE DECISIONS:\\n\"\n",
        "            \n",
        "            for _, row in examples_df.iterrows():\n",
        "                decision_label = \"INCLUDE\" if row['decision'].upper() == 'INCLUDE' else \"EXCLUDE\"\n",
        "                examples_text += f\"\\n**{decision_label} Example:**\\n\"\n",
        "                examples_text += f\"*Title:* {row['title']}\\n\"\n",
        "                examples_text += f\"*Abstract:* {row['abstract_text'][:200]}{'...' if len(row['abstract_text']) > 200 else ''}\\n\"\n",
        "                examples_text += f\"‚Üí **{decision_label}** ({row['reasoning']})\\n\"\n",
        "            \n",
        "            return examples_text\n",
        "        except Exception as e:\n",
        "            return f\"\\n## EXAMPLES:\\nError loading examples: {e}\\n\"\n",
        "    \n",
        "    # Load prompt components\n",
        "    criteria_text = load_criteria_text(CRITERIA_FILE)\n",
        "    examples_section = load_examples_text(EXAMPLES_FILE) if EXAMPLES_FILE else \"\"\n",
        "    \n",
        "    # Initialize results list\n",
        "    results_list = []\n",
        "    \n",
        "    # Calculate number of batches\n",
        "    total_examples = len(test_samples)\n",
        "    num_batches = (total_examples + batch_size - 1) // batch_size  # Ceiling division\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"üì¶ Processing {total_examples} examples in {num_batches} batch(es)\")\n",
        "        print(f\"‚è±Ô∏è  Estimated time: ~{num_batches * 2} minutes (2 min per batch)\")\n",
        "    \n",
        "    # Process examples in batches\n",
        "    for batch_idx in range(num_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min(start_idx + batch_size, total_examples)\n",
        "        batch_samples = test_samples.iloc[start_idx:end_idx]\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"\\nüîÑ Processing Batch {batch_idx + 1}/{num_batches} (examples {start_idx + 1}-{end_idx})\")\n",
        "        \n",
        "        batch_start_time = time.time()\n",
        "        \n",
        "        for idx, row in batch_samples.iterrows():\n",
        "            sample_number = start_idx + (idx - batch_samples.index[0]) + 1\n",
        "            \n",
        "            try:\n",
        "                # Create complete prompt\n",
        "                complete_prompt = USER_PROMPT_TEMPLATE.format(\n",
        "                    topic=TOPIC,\n",
        "                    domain=DOMAIN,\n",
        "                    criteria_text=criteria_text,\n",
        "                    examples_section=examples_section,\n",
        "                    title=row['title_full'],\n",
        "                    abstract=row['abstract']\n",
        "                )\n",
        "                \n",
        "                # Call LLM\n",
        "                llm_result = screen_abstract_llm(\n",
        "                    abstract_text=complete_prompt,\n",
        "                    system_prompt=SYSTEM_PROMPT,\n",
        "                    user_prompt_template=\"{abstract}\",  # Just pass through since we formatted above\n",
        "                    model=MODEL_NAME,\n",
        "                    temperature=TEMPERATURE\n",
        "                )\n",
        "                \n",
        "                # Parse LLM decision - extract Likert score from response\n",
        "                llm_reasoning = llm_result.get('reasoning', 'No reasoning provided')\n",
        "                \n",
        "                # Extract Likert score (1-5) from the response\n",
        "                llm_score = None\n",
        "                for score in ['5', '4', '3', '2', '1']:  # Check in order of preference\n",
        "                    if f\"Relevance Score:** {score}\" in llm_reasoning or f\"**{score}\" in llm_reasoning:\n",
        "                        llm_score = int(score)\n",
        "                        break\n",
        "                \n",
        "                # Fallback: look for any number 1-5 in the response\n",
        "                if llm_score is None:\n",
        "                    import re\n",
        "                    scores = re.findall(r'\\b[1-5]\\b', llm_reasoning)\n",
        "                    if scores:\n",
        "                        llm_score = int(scores[0])\n",
        "                    else:\n",
        "                        llm_score = 3  # Default to middle score if no score found\n",
        "                \n",
        "                # Convert Likert scores to binary for evaluation\n",
        "                # Stage 2: 3,4,5 = positive (worth further review)\n",
        "                stage2_llm_binary = 1 if llm_score >= 3 else 0\n",
        "                # Stage 3: 4,5 = positive (definitely include)  \n",
        "                stage3_llm_binary = 1 if llm_score >= 4 else 0\n",
        "                \n",
        "                stage2_binary = 1 if row['stage_2'] else 0\n",
        "                stage3_binary = 1 if row['stage_3'] else 0\n",
        "                \n",
        "                # Store result\n",
        "                result_row = {\n",
        "                    'example_id': sample_number,\n",
        "                    'title': row['title_full'],\n",
        "                    'abstract': row['abstract'],\n",
        "                    'stage_2_true': row['stage_2'],\n",
        "                    'stage_3_true': row['stage_3'],\n",
        "                    'stage_2_binary': stage2_binary,\n",
        "                    'stage_3_binary': stage3_binary,\n",
        "                    'llm_score': llm_score,  # New: Likert score (1-5)\n",
        "                    'llm_decision': str(llm_score),  # For compatibility\n",
        "                    'stage2_llm_binary': stage2_llm_binary,  # New: Binary for stage 2 (3+ = positive)\n",
        "                    'stage3_llm_binary': stage3_llm_binary,  # New: Binary for stage 3 (4+ = positive)\n",
        "                    'llm_reasoning': llm_reasoning,\n",
        "                    'experiment_id': EXPERIMENT_ID,\n",
        "                    'dataset_source': dataset_source,\n",
        "                    'system_prompt_id': SYSTEM_PROMPT_ID,\n",
        "                    'user_prompt_id': USER_PROMPT_ID,\n",
        "                    'model': MODEL_NAME,\n",
        "                    'temperature': TEMPERATURE,\n",
        "                    'timestamp': datetime.now().isoformat()\n",
        "                }\n",
        "                \n",
        "                results_list.append(result_row)\n",
        "                \n",
        "            except Exception as e:\n",
        "                if verbose:\n",
        "                    print(f\"‚ùå Error processing example {sample_number}: {e}\")\n",
        "                \n",
        "                # Store error result\n",
        "                result_row = {\n",
        "                    'example_id': sample_number,\n",
        "                    'title': row['title_full'],\n",
        "                    'abstract': row['abstract'],\n",
        "                    'stage_2_true': row['stage_2'],\n",
        "                    'stage_3_true': row['stage_3'],\n",
        "                    'stage_2_binary': 1 if row['stage_2'] else 0,\n",
        "                    'stage_3_binary': 1 if row['stage_3'] else 0,\n",
        "                    'llm_score': 0,  # Error case\n",
        "                    'llm_decision': 'ERROR',\n",
        "                    'stage2_llm_binary': 0,\n",
        "                    'stage3_llm_binary': 0,\n",
        "                    'llm_reasoning': f'Processing error: {e}',\n",
        "                    'experiment_id': EXPERIMENT_ID,\n",
        "                    'dataset_source': dataset_source,\n",
        "                    'system_prompt_id': SYSTEM_PROMPT_ID,\n",
        "                    'user_prompt_id': USER_PROMPT_ID,\n",
        "                    'model': MODEL_NAME,\n",
        "                    'temperature': TEMPERATURE,\n",
        "                    'timestamp': datetime.now().isoformat()\n",
        "                }\n",
        "                \n",
        "                results_list.append(result_row)\n",
        "        \n",
        "        # Batch completion info\n",
        "        batch_time = time.time() - batch_start_time\n",
        "        if verbose:\n",
        "            print(f\"‚úÖ Batch {batch_idx + 1} completed in {batch_time:.1f}s\")\n",
        "            if batch_idx < num_batches - 1:  # Not the last batch\n",
        "                print(f\"‚è≥ Brief pause before next batch...\")\n",
        "                time.sleep(2)  # Small delay between batches\n",
        "    \n",
        "    # Create results DataFrame\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "    \n",
        "    # Filter out errors for analysis\n",
        "    valid_results = results_df[results_df['llm_decision'] != 'ERROR']\n",
        "    \n",
        "    # LIKERT SCALE ANALYSIS\n",
        "    if len(valid_results) > 0:\n",
        "        # Overall Likert distribution\n",
        "        likert_counts = valid_results['llm_score'].value_counts().sort_index()\n",
        "        \n",
        "        # Likert distribution by Stage 2 ground truth\n",
        "        stage2_true_scores = valid_results[valid_results['stage_2_true'] == True]['llm_score'].value_counts().sort_index()\n",
        "        stage2_false_scores = valid_results[valid_results['stage_2_true'] == False]['llm_score'].value_counts().sort_index()\n",
        "        \n",
        "        # Likert distribution by Stage 3 ground truth\n",
        "        stage3_true_scores = valid_results[valid_results['stage_3_true'] == True]['llm_score'].value_counts().sort_index()\n",
        "        stage3_false_scores = valid_results[valid_results['stage_3_true'] == False]['llm_score'].value_counts().sort_index()\n",
        "        \n",
        "        # BINARY CLASSIFICATION METRICS\n",
        "        # Stage 2 evaluation (3,4,5 vs 1,2)\n",
        "        y_true_stage2 = valid_results['stage_2_binary'].values\n",
        "        y_pred_stage2 = valid_results['stage2_llm_binary'].values\n",
        "        \n",
        "        accuracy_stage2 = accuracy_score(y_true_stage2, y_pred_stage2)\n",
        "        precision_stage2 = precision_score(y_true_stage2, y_pred_stage2, zero_division=0)\n",
        "        recall_stage2 = recall_score(y_true_stage2, y_pred_stage2, zero_division=0)\n",
        "        f1_stage2 = f1_score(y_true_stage2, y_pred_stage2, zero_division=0)\n",
        "        tn2, fp2, fn2, tp2 = confusion_matrix(y_true_stage2, y_pred_stage2).ravel()\n",
        "        \n",
        "        # Stage 3 evaluation (4,5 vs 1,2,3)\n",
        "        y_true_stage3 = valid_results['stage_3_binary'].values\n",
        "        y_pred_stage3 = valid_results['stage3_llm_binary'].values\n",
        "        \n",
        "        accuracy_stage3 = accuracy_score(y_true_stage3, y_pred_stage3)\n",
        "        precision_stage3 = precision_score(y_true_stage3, y_pred_stage3, zero_division=0)\n",
        "        recall_stage3 = recall_score(y_true_stage3, y_pred_stage3, zero_division=0)\n",
        "        f1_stage3 = f1_score(y_true_stage3, y_pred_stage3, zero_division=0)\n",
        "        tn3, fp3, fn3, tp3 = confusion_matrix(y_true_stage3, y_pred_stage3).ravel()\n",
        "        \n",
        "    else:\n",
        "        # Handle case with no valid results\n",
        "        likert_counts = pd.Series(dtype=int)\n",
        "        stage2_true_scores = stage2_false_scores = pd.Series(dtype=int)\n",
        "        stage3_true_scores = stage3_false_scores = pd.Series(dtype=int)\n",
        "        accuracy_stage2 = precision_stage2 = recall_stage2 = f1_stage2 = 0.0\n",
        "        accuracy_stage3 = precision_stage3 = recall_stage3 = f1_stage3 = 0.0\n",
        "        tp2 = fp2 = tn2 = fn2 = tp3 = fp3 = tn3 = fn3 = 0\n",
        "    \n",
        "    # Updated metrics dictionary with Likert analysis\n",
        "    metrics = {\n",
        "        'stage_2_metrics': {\n",
        "            'accuracy': accuracy_stage2,\n",
        "            'precision': precision_stage2,\n",
        "            'recall': recall_stage2,\n",
        "            'f1_score': f1_stage2,\n",
        "            'tp': int(tp2),\n",
        "            'fp': int(fp2),\n",
        "            'tn': int(tn2),\n",
        "            'fn': int(fn2),\n",
        "            'threshold': '3+ (moderate to high relevance)'\n",
        "        },\n",
        "        'stage_3_metrics': {\n",
        "            'accuracy': accuracy_stage3,\n",
        "            'precision': precision_stage3,\n",
        "            'recall': recall_stage3,\n",
        "            'f1_score': f1_stage3,\n",
        "            'tp': int(tp3),\n",
        "            'fp': int(fp3),\n",
        "            'tn': int(tn3),\n",
        "            'fn': int(fn3),\n",
        "            'threshold': '4+ (high relevance)'\n",
        "        },\n",
        "        'likert_analysis': {\n",
        "            'overall_distribution': {f'score_{i}': int(likert_counts.get(i, 0)) for i in range(1, 6)},\n",
        "            'stage2_true_distribution': {f'score_{i}': int(stage2_true_scores.get(i, 0)) for i in range(1, 6)},\n",
        "            'stage2_false_distribution': {f'score_{i}': int(stage2_false_scores.get(i, 0)) for i in range(1, 6)},\n",
        "            'stage3_true_distribution': {f'score_{i}': int(stage3_true_scores.get(i, 0)) for i in range(1, 6)},\n",
        "            'stage3_false_distribution': {f'score_{i}': int(stage3_false_scores.get(i, 0)) for i in range(1, 6)}\n",
        "        },\n",
        "        'total_examples': len(results_df),\n",
        "        'successful_classifications': len(valid_results),\n",
        "        'errors': len(results_df) - len(valid_results)\n",
        "    }\n",
        "    \n",
        "    # Enhanced results printing\n",
        "    if verbose:\n",
        "        print(f\"\\nüìä EXPERIMENT RESULTS\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"üìä Likert Scale Distribution:\")\n",
        "        for i in range(1, 6):\n",
        "            count = likert_counts.get(i, 0)\n",
        "            print(f\"   Score {i}: {count}\")\n",
        "        \n",
        "        print(f\"\\nüìà Stage 2 Evaluation (3+ = positive):\")\n",
        "        print(f\"   Accuracy:  {accuracy_stage2:.3f}\")\n",
        "        print(f\"   Precision: {precision_stage2:.3f}\")\n",
        "        print(f\"   Recall:    {recall_stage2:.3f}\")\n",
        "        print(f\"   F1 Score:  {f1_stage2:.3f}\")\n",
        "        print(f\"   TP: {tp2}, FP: {fp2}, TN: {tn2}, FN: {fn2}\")\n",
        "        \n",
        "        print(f\"\\nüìà Stage 3 Evaluation (4+ = positive):\")\n",
        "        print(f\"   Accuracy:  {accuracy_stage3:.3f}\")\n",
        "        print(f\"   Precision: {precision_stage3:.3f}\")\n",
        "        print(f\"   Recall:    {recall_stage3:.3f}\")\n",
        "        print(f\"   F1 Score:  {f1_stage3:.3f}\")\n",
        "        print(f\"   TP: {tp3}, FP: {fp3}, TN: {tn3}, FN: {fn3}\")\n",
        "        \n",
        "        print(f\"\\nüìä Score Distribution by Ground Truth:\")\n",
        "        print(f\"   Stage 2 True:  [1:{stage2_true_scores.get(1,0)}, 2:{stage2_true_scores.get(2,0)}, 3:{stage2_true_scores.get(3,0)}, 4:{stage2_true_scores.get(4,0)}, 5:{stage2_true_scores.get(5,0)}]\")\n",
        "        print(f\"   Stage 2 False: [1:{stage2_false_scores.get(1,0)}, 2:{stage2_false_scores.get(2,0)}, 3:{stage2_false_scores.get(3,0)}, 4:{stage2_false_scores.get(4,0)}, 5:{stage2_false_scores.get(5,0)}]\")\n",
        "        print(f\"   Stage 3 True:  [1:{stage3_true_scores.get(1,0)}, 2:{stage3_true_scores.get(2,0)}, 3:{stage3_true_scores.get(3,0)}, 4:{stage3_true_scores.get(4,0)}, 5:{stage3_true_scores.get(5,0)}]\")\n",
        "        print(f\"   Stage 3 False: [1:{stage3_false_scores.get(1,0)}, 2:{stage3_false_scores.get(2,0)}, 3:{stage3_false_scores.get(3,0)}, 4:{stage3_false_scores.get(4,0)}, 5:{stage3_false_scores.get(5,0)}]\")\n",
        "        \n",
        "        print(f\"\\nüìã Processing Summary:\")\n",
        "        print(f\"   Total examples: {len(results_df)}\")\n",
        "        print(f\"   Successful: {len(valid_results)}\")\n",
        "        print(f\"   Errors: {len(results_df) - len(valid_results)}\")\n",
        "    \n",
        "    # Save results\n",
        "    if save_results:\n",
        "        # Create filename with timestamp\n",
        "        timestamp = datetime.now().strftime(\"%m%d%H%M\")\n",
        "        filename = f\"{EXPERIMENT_ID}_{dataset_source}_{timestamp}.csv\"\n",
        "        results_dir = \"../results\"\n",
        "        os.makedirs(results_dir, exist_ok=True)\n",
        "        output_path = os.path.join(results_dir, filename)\n",
        "        \n",
        "        results_df.to_csv(output_path, index=False)\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"\\nüíæ Results saved to: {output_path}\")\n",
        "    \n",
        "    return {\n",
        "        'results_df': results_df,\n",
        "        'metrics': metrics,\n",
        "        'filename': filename if save_results else None\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Classification experiment function with Likert scale analysis defined\")\n",
        "print(\"üöÄ Ready to run: run_classification_experiment(df_BM, batch_size=20)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Run experiment! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Starting Classification Experiment with Batch Processing\n",
            "üìä Dataset: BM\n",
            "üéØ Total examples: 50\n",
            "‚úÖ Stage 3 True: 5\n",
            "‚ùå Stage 3 False: 45\n",
            "üì¶ Batch size: 20\n",
            "==================================================\n",
            "üìù Sampled 50 examples\n",
            "üì¶ Processing 50 examples in 3 batch(es)\n",
            "‚è±Ô∏è  Estimated time: ~6 minutes (2 min per batch)\n",
            "\n",
            "üîÑ Processing Batch 1/3 (examples 1-20)\n",
            "‚úÖ Batch 1 completed in 154.0s\n",
            "‚è≥ Brief pause before next batch...\n",
            "\n",
            "üîÑ Processing Batch 2/3 (examples 21-40)\n",
            "‚úÖ Batch 2 completed in 160.4s\n",
            "‚è≥ Brief pause before next batch...\n",
            "\n",
            "üîÑ Processing Batch 3/3 (examples 41-50)\n",
            "‚úÖ Batch 3 completed in 77.7s\n",
            "\n",
            "üìä EXPERIMENT RESULTS\n",
            "==================================================\n",
            "üìä Likert Scale Distribution:\n",
            "   Score 1: 34\n",
            "   Score 2: 10\n",
            "   Score 3: 3\n",
            "   Score 4: 2\n",
            "   Score 5: 1\n",
            "\n",
            "üìà Stage 2 Evaluation (3+ = positive):\n",
            "   Accuracy:  0.880\n",
            "   Precision: 0.833\n",
            "   Recall:    0.500\n",
            "   F1 Score:  0.625\n",
            "   TP: 5, FP: 1, TN: 39, FN: 5\n",
            "\n",
            "üìà Stage 3 Evaluation (4+ = positive):\n",
            "   Accuracy:  0.960\n",
            "   Precision: 1.000\n",
            "   Recall:    0.600\n",
            "   F1 Score:  0.750\n",
            "   TP: 3, FP: 0, TN: 45, FN: 2\n",
            "\n",
            "üìä Score Distribution by Ground Truth:\n",
            "   Stage 2 True:  [1:2, 2:3, 3:2, 4:2, 5:1]\n",
            "   Stage 2 False: [1:32, 2:7, 3:1, 4:0, 5:0]\n",
            "   Stage 3 True:  [1:0, 2:1, 3:1, 4:2, 5:1]\n",
            "   Stage 3 False: [1:34, 2:9, 3:2, 4:0, 5:0]\n",
            "\n",
            "üìã Processing Summary:\n",
            "   Total examples: 50\n",
            "   Successful: 50\n",
            "   Errors: 0\n",
            "\n",
            "üíæ Results saved to: ../results/016_BM_08141334.csv\n"
          ]
        }
      ],
      "source": [
        "# Run experiment with default settings\n",
        "results = run_classification_experiment(df_BM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Results Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load results file - you can specify the exact file path here\n",
        "RESULTS_FILE_PATH = \"../results/0002_LB_08131412.csv\"  # ‚¨ÖÔ∏è Change this to your specific file path\n",
        "\n",
        "# Alternative: Set to None to auto-load the most recent file\n",
        "# RESULTS_FILE_PATH = None\n",
        "\n",
        "if RESULTS_FILE_PATH:\n",
        "    # Load specific file\n",
        "    if os.path.exists(RESULTS_FILE_PATH):\n",
        "        print(f\"üìÅ Loading specified file: {os.path.basename(RESULTS_FILE_PATH)}\")\n",
        "        df_results = pd.read_csv(RESULTS_FILE_PATH)\n",
        "    else:\n",
        "        print(f\"‚ùå Error: File not found: {RESULTS_FILE_PATH}\")\n",
        "        df_results = None\n",
        "else:\n",
        "    # Auto-load most recent file (original behavior)\n",
        "    results_dir = \"../results\"\n",
        "    result_files = [f for f in os.listdir(results_dir) if f.endswith('.csv')]\n",
        "    if result_files:\n",
        "        latest_file = sorted(result_files)[-1]\n",
        "        file_path = os.path.join(results_dir, latest_file)\n",
        "        print(f\"üìÅ Auto-loading most recent file: {latest_file}\")\n",
        "        df_results = pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"‚ùå No result files found in ../results directory\")\n",
        "        df_results = None\n",
        "\n",
        "# Continue with analysis if file was loaded successfully\n",
        "if df_results is not None:\n",
        "    print(f\"\\nüìä RESULTS OVERVIEW\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Shape: {df_results.shape}\")\n",
        "    print(f\"Columns: {list(df_results.columns)}\")\n",
        "    \n",
        "    print(f\"\\nüéØ DECISION SUMMARY\")\n",
        "    print(\"=\" * 30)\n",
        "    print(df_results['llm_decision'].value_counts())\n",
        "    \n",
        "    print(f\"\\nüìà PERFORMANCE PREVIEW\")\n",
        "    print(\"=\" * 30)\n",
        "    print(\"Stage 2 vs LLM:\")\n",
        "    print(pd.crosstab(df_results['stage_2_true'], df_results['llm_decision']))\n",
        "    print(\"\\nStage 3 vs LLM:\")\n",
        "    print(pd.crosstab(df_results['stage_3_true'], df_results['llm_decision']))\n",
        "    \n",
        "    print(f\"\\nüìã FIRST FEW RESULTS\")\n",
        "    print(\"=\" * 30)\n",
        "    display(df_results[['example_id', 'stage_2_true', 'stage_3_true', 'llm_decision', 'llm_reasoning']].head())\n",
        "else:\n",
        "    print(\"‚ùå Could not load results file for analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display full reasoning for first 5 examples\n",
        "print(\"ü§ñ FULL LLM REASONING EXAMPLES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for idx in range(min(5, len(df_results))):\n",
        "    row = df_results.iloc[idx]\n",
        "    print(f\"\\nüìã EXAMPLE {row['example_id']} - {row['llm_decision']}\")\n",
        "    print(f\"üéØ Ground Truth: Stage 2={row['stage_2_true']}, Stage 3={row['stage_3_true']}\")\n",
        "    print(f\"üìñ Title: {row['title'][:100]}{'...' if len(row['title']) > 100 else ''}\")\n",
        "    print(f\"\\nüí≠ FULL REASONING:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(row['llm_reasoning'])\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ûï Add experiment info to the results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Added experiment 016 to existing summary\n",
            "üíæ Summary saved to: ../results/experiment_summary.csv\n",
            "\n",
            "üìã LAST 5 EXPERIMENTS IN SUMMARY:\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>experiment_id</th>\n",
              "      <th>experiment_date</th>\n",
              "      <th>experiment_category</th>\n",
              "      <th>experiment_goal</th>\n",
              "      <th>system_prompt_id</th>\n",
              "      <th>user_prompt_id</th>\n",
              "      <th>model_name</th>\n",
              "      <th>temperature</th>\n",
              "      <th>max_tokens</th>\n",
              "      <th>criteria_file</th>\n",
              "      <th>examples_file</th>\n",
              "      <th>output_format</th>\n",
              "      <th>domain</th>\n",
              "      <th>topic</th>\n",
              "      <th>dataset_source</th>\n",
              "      <th>n_total_examples</th>\n",
              "      <th>n_successful</th>\n",
              "      <th>n_errors</th>\n",
              "      <th>stage2_accuracy</th>\n",
              "      <th>stage2_precision</th>\n",
              "      <th>stage2_recall</th>\n",
              "      <th>stage2_f1</th>\n",
              "      <th>stage2_tp</th>\n",
              "      <th>stage2_fp</th>\n",
              "      <th>stage2_tn</th>\n",
              "      <th>stage2_fn</th>\n",
              "      <th>stage3_accuracy</th>\n",
              "      <th>stage3_precision</th>\n",
              "      <th>stage3_recall</th>\n",
              "      <th>stage3_f1</th>\n",
              "      <th>stage3_tp</th>\n",
              "      <th>stage3_fp</th>\n",
              "      <th>stage3_tn</th>\n",
              "      <th>stage3_fn</th>\n",
              "      <th>results_filename</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>llm_include_count</th>\n",
              "      <th>llm_maybe_count</th>\n",
              "      <th>llm_exclude_count</th>\n",
              "      <th>llm_error_count</th>\n",
              "      <th>likert_score_1</th>\n",
              "      <th>likert_score_2</th>\n",
              "      <th>likert_score_3</th>\n",
              "      <th>likert_score_4</th>\n",
              "      <th>likert_score_5</th>\n",
              "      <th>stage2_true_score_1</th>\n",
              "      <th>stage2_true_score_2</th>\n",
              "      <th>stage2_true_score_3</th>\n",
              "      <th>stage2_true_score_4</th>\n",
              "      <th>stage2_true_score_5</th>\n",
              "      <th>stage2_false_score_1</th>\n",
              "      <th>stage2_false_score_2</th>\n",
              "      <th>stage2_false_score_3</th>\n",
              "      <th>stage2_false_score_4</th>\n",
              "      <th>stage2_false_score_5</th>\n",
              "      <th>stage3_true_score_1</th>\n",
              "      <th>stage3_true_score_2</th>\n",
              "      <th>stage3_true_score_3</th>\n",
              "      <th>stage3_true_score_4</th>\n",
              "      <th>stage3_true_score_5</th>\n",
              "      <th>stage3_false_score_1</th>\n",
              "      <th>stage3_false_score_2</th>\n",
              "      <th>stage3_false_score_3</th>\n",
              "      <th>stage3_false_score_4</th>\n",
              "      <th>stage3_false_score_5</th>\n",
              "      <th>stage2_threshold</th>\n",
              "      <th>stage3_threshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>2025-08-14</td>\n",
              "      <td>Testing</td>\n",
              "      <td>Test Set Up</td>\n",
              "      <td>SYS_001</td>\n",
              "      <td>USR_001</td>\n",
              "      <td>gpt-4o</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4000</td>\n",
              "      <td>../prompts/Criteria_BM_01.csv</td>\n",
              "      <td>../prompts/exmpl_five_BM_01.csv</td>\n",
              "      <td>Binary</td>\n",
              "      <td>political_communication</td>\n",
              "      <td>Computational Text Analysis Methods</td>\n",
              "      <td>BM</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.840</td>\n",
              "      <td>0.667</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.500</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "      <td>6</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.667</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.727</td>\n",
              "      <td>4.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>43.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>012_BM_08141308.csv</td>\n",
              "      <td>2025-08-14T13:09:04.489721</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>2025-08-14</td>\n",
              "      <td>Testing</td>\n",
              "      <td>Test Set Up</td>\n",
              "      <td>SYS_001</td>\n",
              "      <td>USR_003</td>\n",
              "      <td>gpt-4o</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4000</td>\n",
              "      <td>../prompts/Criteria_BM_01.csv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes/Maybe/No</td>\n",
              "      <td>political_communication</td>\n",
              "      <td>Computational Text Analysis Methods</td>\n",
              "      <td>BM</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.860</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.533</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>013_BM_08141313.csv</td>\n",
              "      <td>2025-08-14T13:14:14.235853</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>45.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>2025-08-14</td>\n",
              "      <td>Testing</td>\n",
              "      <td>Test Set Up</td>\n",
              "      <td>SYS_001</td>\n",
              "      <td>USR_004</td>\n",
              "      <td>gpt-4o</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4000</td>\n",
              "      <td>../prompts/Criteria_BM_01.csv</td>\n",
              "      <td>../prompts/exmpl_single_BM_01.csv</td>\n",
              "      <td>Yes/Maybe/No</td>\n",
              "      <td>political_communication</td>\n",
              "      <td>Computational Text Analysis Methods</td>\n",
              "      <td>BM</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.860</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.462</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>014_BM_08141316.csv</td>\n",
              "      <td>2025-08-14T13:19:18.530402</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>47.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>2025-08-14</td>\n",
              "      <td>Testing</td>\n",
              "      <td>Test Set Up</td>\n",
              "      <td>SYS_001</td>\n",
              "      <td>USR_004</td>\n",
              "      <td>gpt-4o</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4000</td>\n",
              "      <td>../prompts/Criteria_BM_01.csv</td>\n",
              "      <td>../prompts/exmpl_five_BM_01.csv</td>\n",
              "      <td>Yes/Maybe/No</td>\n",
              "      <td>political_communication</td>\n",
              "      <td>Computational Text Analysis Methods</td>\n",
              "      <td>BM</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.840</td>\n",
              "      <td>0.667</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.500</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>015_BM_08141326.csv</td>\n",
              "      <td>2025-08-14T13:28:50.888383</td>\n",
              "      <td>6.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>44.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>016</td>\n",
              "      <td>2025-08-14</td>\n",
              "      <td>Testing</td>\n",
              "      <td>Test Set Up</td>\n",
              "      <td>SYS_001</td>\n",
              "      <td>USR_005</td>\n",
              "      <td>gpt-4o</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4000</td>\n",
              "      <td>../prompts/Criteria_BM_01.csv</td>\n",
              "      <td>None</td>\n",
              "      <td>Likert</td>\n",
              "      <td>political_communication</td>\n",
              "      <td>Computational Text Analysis Methods</td>\n",
              "      <td>BM</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.625</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.960</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.750</td>\n",
              "      <td>3.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>45.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>016_BM_08141334.csv</td>\n",
              "      <td>2025-08-14T13:34:32.727516</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.000</td>\n",
              "      <td>10.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>32.000</td>\n",
              "      <td>7.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>34.000</td>\n",
              "      <td>9.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3+ (moderate to high relevance)</td>\n",
              "      <td>4+ (high relevance)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   experiment_id experiment_date experiment_category experiment_goal system_prompt_id user_prompt_id model_name  temperature  max_tokens                  criteria_file                      examples_file output_format                   domain                                topic dataset_source  n_total_examples  n_successful  n_errors  stage2_accuracy  stage2_precision  stage2_recall  stage2_f1  stage2_tp  stage2_fp  stage2_tn  stage2_fn  stage3_accuracy  stage3_precision  stage3_recall  stage3_f1  stage3_tp  stage3_fp  stage3_tn  stage3_fn     results_filename                   timestamp  llm_include_count  llm_maybe_count  llm_exclude_count  llm_error_count  likert_score_1  likert_score_2  likert_score_3  likert_score_4  likert_score_5  stage2_true_score_1  stage2_true_score_2  stage2_true_score_3  stage2_true_score_4  stage2_true_score_5  stage2_false_score_1  stage2_false_score_2  stage2_false_score_3  stage2_false_score_4  stage2_false_score_5  stage3_true_score_1  \\\n",
              "11            12      2025-08-14             Testing     Test Set Up          SYS_001        USR_001     gpt-4o        0.000        4000  ../prompts/Criteria_BM_01.csv    ../prompts/exmpl_five_BM_01.csv        Binary  political_communication  Computational Text Analysis Methods             BM                50            50         0            0.840             0.667          0.400      0.500          4          2         38          6            0.940             0.667          0.800      0.727      4.000      2.000     43.000      1.000  012_BM_08141308.csv  2025-08-14T13:09:04.489721                NaN              NaN                NaN              NaN             NaN             NaN             NaN             NaN             NaN                  NaN                  NaN                  NaN                  NaN                  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                  NaN   \n",
              "12            13      2025-08-14             Testing     Test Set Up          SYS_001        USR_003     gpt-4o        0.000        4000  ../prompts/Criteria_BM_01.csv                                NaN  Yes/Maybe/No  political_communication  Computational Text Analysis Methods             BM                50            50         0            0.860             0.800          0.400      0.533          4          1         39          6              NaN               NaN            NaN        NaN        NaN        NaN        NaN        NaN  013_BM_08141313.csv  2025-08-14T13:14:14.235853              5.000            0.000             45.000            0.000             NaN             NaN             NaN             NaN             NaN                  NaN                  NaN                  NaN                  NaN                  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                  NaN   \n",
              "13            14      2025-08-14             Testing     Test Set Up          SYS_001        USR_004     gpt-4o        0.000        4000  ../prompts/Criteria_BM_01.csv  ../prompts/exmpl_single_BM_01.csv  Yes/Maybe/No  political_communication  Computational Text Analysis Methods             BM                50            50         0            0.860             1.000          0.300      0.462          3          0         40          7              NaN               NaN            NaN        NaN        NaN        NaN        NaN        NaN  014_BM_08141316.csv  2025-08-14T13:19:18.530402              3.000            0.000             47.000            0.000             NaN             NaN             NaN             NaN             NaN                  NaN                  NaN                  NaN                  NaN                  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                  NaN   \n",
              "14            15      2025-08-14             Testing     Test Set Up          SYS_001        USR_004     gpt-4o        0.000        4000  ../prompts/Criteria_BM_01.csv    ../prompts/exmpl_five_BM_01.csv  Yes/Maybe/No  political_communication  Computational Text Analysis Methods             BM                50            50         0            0.840             0.667          0.400      0.500          4          2         38          6              NaN               NaN            NaN        NaN        NaN        NaN        NaN        NaN  015_BM_08141326.csv  2025-08-14T13:28:50.888383              6.000            0.000             44.000            0.000             NaN             NaN             NaN             NaN             NaN                  NaN                  NaN                  NaN                  NaN                  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                  NaN   \n",
              "15           016      2025-08-14             Testing     Test Set Up          SYS_001        USR_005     gpt-4o        0.000        4000  ../prompts/Criteria_BM_01.csv                               None        Likert  political_communication  Computational Text Analysis Methods             BM                50            50         0            0.880             0.833          0.500      0.625          5          1         39          5            0.960             1.000          0.600      0.750      3.000      0.000     45.000      2.000  016_BM_08141334.csv  2025-08-14T13:34:32.727516                NaN              NaN                NaN              NaN          34.000          10.000           3.000           2.000           1.000                2.000                3.000                2.000                2.000                1.000                32.000                 7.000                 1.000                 0.000                 0.000                0.000   \n",
              "\n",
              "    stage3_true_score_2  stage3_true_score_3  stage3_true_score_4  stage3_true_score_5  stage3_false_score_1  stage3_false_score_2  stage3_false_score_3  stage3_false_score_4  stage3_false_score_5                 stage2_threshold     stage3_threshold  \n",
              "11                  NaN                  NaN                  NaN                  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                              NaN                  NaN  \n",
              "12                  NaN                  NaN                  NaN                  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                              NaN                  NaN  \n",
              "13                  NaN                  NaN                  NaN                  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                              NaN                  NaN  \n",
              "14                  NaN                  NaN                  NaN                  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                              NaN                  NaN  \n",
              "15                1.000                1.000                2.000                1.000                34.000                 9.000                 2.000                 0.000                 0.000  3+ (moderate to high relevance)  4+ (high relevance)  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä LIKERT SCALE SUMMARY FOR EXPERIMENT 016:\n",
            "==================================================\n",
            "Overall Distribution: [1:34, 2:10, 3:3, 4:2, 5:1]\n",
            "Stage 2 True:  [1:2, 2:3, 3:2, 4:2, 5:1]\n",
            "Stage 2 False: [1:32, 2:7, 3:1, 4:0, 5:0]\n",
            "Stage 3 True:  [1:0, 2:1, 3:1, 4:2, 5:1]\n",
            "Stage 3 False: [1:34, 2:9, 3:2, 4:0, 5:0]\n",
            "\n",
            "üìä SUMMARY STATS:\n",
            "   Total experiments: 16\n",
            "   Unique experiment IDs: 16\n",
            "   Datasets used: ['LB', 'BM']\n"
          ]
        }
      ],
      "source": [
        "def add_experiment_to_summary(results_dict, summary_file=\"../results/experiment_summary.csv\"):\n",
        "    \"\"\"Add new experiment results to the summary DataFrame with confusion matrix metrics and Likert analysis\"\"\"\n",
        "    \n",
        "    new_row = pd.DataFrame({\n",
        "        'experiment_id': [EXPERIMENT_ID],\n",
        "        'experiment_date': [EXPERIMENT_DATE],\n",
        "        'experiment_category': [EXPERIMENT_CATEGORY],\n",
        "        'experiment_goal': [EXPERIMENT_GOAL],\n",
        "        'system_prompt_id': [SYSTEM_PROMPT_ID],\n",
        "        'user_prompt_id': [USER_PROMPT_ID],\n",
        "        'model_name': [MODEL_NAME],\n",
        "        'temperature': [TEMPERATURE],\n",
        "        'max_tokens': [MAX_TOKENS],\n",
        "        'criteria_file': [CRITERIA_FILE],\n",
        "        'examples_file': [EXAMPLES_FILE],\n",
        "        'output_format': [OUTPUT_FORMAT],\n",
        "        'domain': [DOMAIN],\n",
        "        'topic': [TOPIC],\n",
        "        'dataset_source': [DATASET_SOURCE],\n",
        "        'n_total_examples': [results_dict['metrics']['total_examples']],\n",
        "        'n_successful': [results_dict['metrics']['successful_classifications']],\n",
        "        'n_errors': [results_dict['metrics']['errors']],\n",
        "        # Stage 2 metrics\n",
        "        'stage2_accuracy': [results_dict['metrics']['stage_2_metrics']['accuracy']],\n",
        "        'stage2_precision': [results_dict['metrics']['stage_2_metrics']['precision']],\n",
        "        'stage2_recall': [results_dict['metrics']['stage_2_metrics']['recall']],\n",
        "        'stage2_f1': [results_dict['metrics']['stage_2_metrics']['f1_score']],\n",
        "        'stage2_tp': [results_dict['metrics']['stage_2_metrics']['tp']],\n",
        "        'stage2_fp': [results_dict['metrics']['stage_2_metrics']['fp']],\n",
        "        'stage2_tn': [results_dict['metrics']['stage_2_metrics']['tn']],\n",
        "        'stage2_fn': [results_dict['metrics']['stage_2_metrics']['fn']],\n",
        "        # Stage 3 metrics\n",
        "        'stage3_accuracy': [results_dict['metrics']['stage_3_metrics']['accuracy']],\n",
        "        'stage3_precision': [results_dict['metrics']['stage_3_metrics']['precision']],\n",
        "        'stage3_recall': [results_dict['metrics']['stage_3_metrics']['recall']],\n",
        "        'stage3_f1': [results_dict['metrics']['stage_3_metrics']['f1_score']],\n",
        "        'stage3_tp': [results_dict['metrics']['stage_3_metrics']['tp']],\n",
        "        'stage3_fp': [results_dict['metrics']['stage_3_metrics']['fp']],\n",
        "        'stage3_tn': [results_dict['metrics']['stage_3_metrics']['tn']],\n",
        "        'stage3_fn': [results_dict['metrics']['stage_3_metrics']['fn']],\n",
        "        # Likert scale overall distribution\n",
        "        'likert_score_1': [results_dict['metrics']['likert_analysis']['overall_distribution']['score_1']],\n",
        "        'likert_score_2': [results_dict['metrics']['likert_analysis']['overall_distribution']['score_2']],\n",
        "        'likert_score_3': [results_dict['metrics']['likert_analysis']['overall_distribution']['score_3']],\n",
        "        'likert_score_4': [results_dict['metrics']['likert_analysis']['overall_distribution']['score_4']],\n",
        "        'likert_score_5': [results_dict['metrics']['likert_analysis']['overall_distribution']['score_5']],\n",
        "        # Likert distribution for Stage 2 True\n",
        "        'stage2_true_score_1': [results_dict['metrics']['likert_analysis']['stage2_true_distribution']['score_1']],\n",
        "        'stage2_true_score_2': [results_dict['metrics']['likert_analysis']['stage2_true_distribution']['score_2']],\n",
        "        'stage2_true_score_3': [results_dict['metrics']['likert_analysis']['stage2_true_distribution']['score_3']],\n",
        "        'stage2_true_score_4': [results_dict['metrics']['likert_analysis']['stage2_true_distribution']['score_4']],\n",
        "        'stage2_true_score_5': [results_dict['metrics']['likert_analysis']['stage2_true_distribution']['score_5']],\n",
        "        # Likert distribution for Stage 2 False\n",
        "        'stage2_false_score_1': [results_dict['metrics']['likert_analysis']['stage2_false_distribution']['score_1']],\n",
        "        'stage2_false_score_2': [results_dict['metrics']['likert_analysis']['stage2_false_distribution']['score_2']],\n",
        "        'stage2_false_score_3': [results_dict['metrics']['likert_analysis']['stage2_false_distribution']['score_3']],\n",
        "        'stage2_false_score_4': [results_dict['metrics']['likert_analysis']['stage2_false_distribution']['score_4']],\n",
        "        'stage2_false_score_5': [results_dict['metrics']['likert_analysis']['stage2_false_distribution']['score_5']],\n",
        "        # Likert distribution for Stage 3 True\n",
        "        'stage3_true_score_1': [results_dict['metrics']['likert_analysis']['stage3_true_distribution']['score_1']],\n",
        "        'stage3_true_score_2': [results_dict['metrics']['likert_analysis']['stage3_true_distribution']['score_2']],\n",
        "        'stage3_true_score_3': [results_dict['metrics']['likert_analysis']['stage3_true_distribution']['score_3']],\n",
        "        'stage3_true_score_4': [results_dict['metrics']['likert_analysis']['stage3_true_distribution']['score_4']],\n",
        "        'stage3_true_score_5': [results_dict['metrics']['likert_analysis']['stage3_true_distribution']['score_5']],\n",
        "        # Likert distribution for Stage 3 False\n",
        "        'stage3_false_score_1': [results_dict['metrics']['likert_analysis']['stage3_false_distribution']['score_1']],\n",
        "        'stage3_false_score_2': [results_dict['metrics']['likert_analysis']['stage3_false_distribution']['score_2']],\n",
        "        'stage3_false_score_3': [results_dict['metrics']['likert_analysis']['stage3_false_distribution']['score_3']],\n",
        "        'stage3_false_score_4': [results_dict['metrics']['likert_analysis']['stage3_false_distribution']['score_4']],\n",
        "        'stage3_false_score_5': [results_dict['metrics']['likert_analysis']['stage3_false_distribution']['score_5']],\n",
        "        # Thresholds for documentation\n",
        "        'stage2_threshold': [results_dict['metrics']['stage_2_metrics']['threshold']],\n",
        "        'stage3_threshold': [results_dict['metrics']['stage_3_metrics']['threshold']],\n",
        "        # Existing columns\n",
        "        'results_filename': [results_dict['filename']],\n",
        "        'timestamp': [datetime.now().isoformat()]\n",
        "    })\n",
        "    \n",
        "    # Load existing summary or create new one\n",
        "    if os.path.exists(summary_file):\n",
        "        existing_summary = pd.read_csv(summary_file)\n",
        "        updated_summary = pd.concat([existing_summary, new_row], ignore_index=True)\n",
        "        print(f\"‚úÖ Added experiment {EXPERIMENT_ID} to existing summary\")\n",
        "    else:\n",
        "        updated_summary = new_row\n",
        "        print(f\"‚úÖ Created new summary file with experiment {EXPERIMENT_ID}\")\n",
        "    \n",
        "    # Save updated summary\n",
        "    updated_summary.to_csv(summary_file, index=False)\n",
        "    print(f\"üíæ Summary saved to: {summary_file}\")\n",
        "    \n",
        "    # Display last 5 rows for verification\n",
        "    print(f\"\\nüìã LAST 5 EXPERIMENTS IN SUMMARY:\")\n",
        "    print(\"=\" * 50)\n",
        "    display(updated_summary.tail())\n",
        "    \n",
        "    # Display Likert summary for the new experiment\n",
        "    print(f\"\\nüìä LIKERT SCALE SUMMARY FOR EXPERIMENT {EXPERIMENT_ID}:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Overall Distribution: [1:{new_row['likert_score_1'].iloc[0]}, 2:{new_row['likert_score_2'].iloc[0]}, 3:{new_row['likert_score_3'].iloc[0]}, 4:{new_row['likert_score_4'].iloc[0]}, 5:{new_row['likert_score_5'].iloc[0]}]\")\n",
        "    print(f\"Stage 2 True:  [1:{new_row['stage2_true_score_1'].iloc[0]}, 2:{new_row['stage2_true_score_2'].iloc[0]}, 3:{new_row['stage2_true_score_3'].iloc[0]}, 4:{new_row['stage2_true_score_4'].iloc[0]}, 5:{new_row['stage2_true_score_5'].iloc[0]}]\")\n",
        "    print(f\"Stage 2 False: [1:{new_row['stage2_false_score_1'].iloc[0]}, 2:{new_row['stage2_false_score_2'].iloc[0]}, 3:{new_row['stage2_false_score_3'].iloc[0]}, 4:{new_row['stage2_false_score_4'].iloc[0]}, 5:{new_row['stage2_false_score_5'].iloc[0]}]\")\n",
        "    print(f\"Stage 3 True:  [1:{new_row['stage3_true_score_1'].iloc[0]}, 2:{new_row['stage3_true_score_2'].iloc[0]}, 3:{new_row['stage3_true_score_3'].iloc[0]}, 4:{new_row['stage3_true_score_4'].iloc[0]}, 5:{new_row['stage3_true_score_5'].iloc[0]}]\")\n",
        "    print(f\"Stage 3 False: [1:{new_row['stage3_false_score_1'].iloc[0]}, 2:{new_row['stage3_false_score_2'].iloc[0]}, 3:{new_row['stage3_false_score_3'].iloc[0]}, 4:{new_row['stage3_false_score_4'].iloc[0]}, 5:{new_row['stage3_false_score_5'].iloc[0]}]\")\n",
        "    \n",
        "    print(f\"\\nüìä SUMMARY STATS:\")\n",
        "    print(f\"   Total experiments: {len(updated_summary)}\")\n",
        "    print(f\"   Unique experiment IDs: {updated_summary['experiment_id'].nunique()}\")\n",
        "    print(f\"   Datasets used: {updated_summary['dataset_source'].unique().tolist()}\")\n",
        "    \n",
        "    return updated_summary\n",
        "\n",
        "# Usage example (uncomment to run):\n",
        "summary_df = add_experiment_to_summary(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Conclusions and Next Steps\n",
        "\n",
        "### Key Findings\n",
        "- \n",
        "\n",
        "### Next Steps\n",
        "- [Suggest follow-up experiments]\n",
        "- [List potential improvements]\n",
        "- [Identify areas for further investigation]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "SLRenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
